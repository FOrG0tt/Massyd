from flask import Flask, render_template, Response
from PIL import Image, ImageDraw, ImageFont
from object_detection.utils import label_map_util
from object_detection.utils import visualization_utils as vis_utils
from aip import AipBodyAnalysis
import threading
import time
import cv2
import numpy as np
import socket
import struct
import os
import re
import demjson
import pyzbar.pyzbar as pyzbar
import ctypes
import inspect
import select
import bobot_megs_car
import HSV_Config
import PID
import tensorflow as tf
import re
import numpy as np
import RPi.GPIO as GPIO

# Global variables
global PASSWD, g_tag_select, g_drive_view_switch, g_connect_wifi_switch, g_servormode
global meanshift_Y, car_speed, prev_left, qrcode_data, meanshift_X, SSID, color_hsv
global g_motormode, prev_right, meanshift_width, updownpulse, g_track_mode, gesture_date
global g_target_mode, meanshift_update_flag, g_init, color_upper, leftrightpulse
global g_presentation_mode, g_mode, g_detect_control_mode, g_detdect_mode, g_auto_drive_switch
global LED1_state, meanshift_high, g_tag_identify_switch, color_lower

# Constants
APP_ID_Body = 'no'
API_KEY_Body = 'no'
SECRET_KEY_Body = 'no'
client_body = AipBodyAnalysis(APP_ID_Body, API_KEY_Body, SECRET_KEY_Body)
LED1 = 40
LED2 = 38
Buzzer = 32
EchoPin = 18
TrigPin = 16
AvoidSensorLeft = 21
AvoidSensorRight = 19
Avoid_ON = 22
SSID = ''
PASSWD = ''
meanshift_X = 140
meanshift_Y = 100
meanshift_width = 40
meanshift_high = 40
meanshift_update_flag = 0
prev_left = 0
prev_right = 0
LED1_state = False
g_init = False
leftrightpulse = 1400 # Initial Pulse Width
updownpulse = 1400 # Initial Pulse Width
color_lower = np.array([156, 43, 46])
color_upper = np.array([180, 255, 255])
color_hsv = {
    'red': ((0, 70, 72), (7, 255, 255)),
    'green': ((54, 109, 78), (77, 255, 255)),
    'blue': ((92, 100, 62), (121, 251, 255)),
    'yellow': ((26, 100, 91), (32, 255, 255))
}
car_speed = 100
qrcode_data = '0'
gesture_date = '0'
g_mode = '0'
g_servormode = '0'
g_motormode = 'car_stop'
g_detdect_mode = '0'
g_target_mode = '0'
g_tag_select = '0'
g_tag_identify_switch = 'close'
g_presentation_mode = '0'
g_track_mode = '0'
g_detect_control_mode = '0'
g_drive_view_switch = 0
g_auto_drive_switch = 'close'
g_connect_wifi_switch = 'close'
HANDSHAKE_STRING = 'HTTP/1.1 101 Switching Protocols\r\nUpgrade:websocket\r\nConnection: Upgrade\r\nSec-WebSocket-Accept: {1}\r\nWebSocket-Location: ws://{2}/chat\r\nWebSocket-Protocol:chat\r\n\r\n'
app = Flask(__name__)
car = bobot_megs_car.bobot_megs_car()

@app.route('/')
def index():
    """
    Render the index page.
    
    This function handles the root URL of the web application.
    When a user accesses the root URL, it will render and return the 'index.html' template.
    """
    print('index')
    return render_template('index.html')

@app.route('/video_feed')
def video_feed():
    """
    Provide video feed.

    This function handles the '/video_feed' URL.
    When accessed, it will return a video stream from the camera.
    The video stream is generated by the 'mode_handle' function and is sent as a multipart response.
    """
    print('video_feed')
    return Response(mode_handle(), mimetype='multipart/x-mixed-replace; boundary=frame')

@app.route('/init')
def init():
    """
    Initialize the websocket server.

    This function handles the '/init' URL.
    When accessed, it will start a new thread to run the TCP server if it is not already running.
    The TCP server listens for incoming connections on port 6000.
    """
    global tid
    if not g_init:
        # Create and start a new thread to run the TCP server
        tid = threading.Thread(target=start_tcp_server, args=(6000,))
        tid.setDaemon(True)
        tid.start()
    print('init websocket!')
    return render_template('init.html')

def _async_raise(tid, exctype):
    """
    Raise an exception in a thread.

    This function allows you to raise an exception in a thread, which can be useful for stopping a thread.
    It uses the ctypes module to interact with the low-level Python API.

    Args:
        tid (int): The thread ID.
        exctype (type): The exception type to be raised.

    Raises:
        ValueError: If the thread ID is invalid.
    """
    # Convert the thread ID to a C long integer
    tid = ctypes.c_long(tid)
    
    # Ensure the exception type is a class
    if not inspect.isclass(exctype):
        exctype = type(exctype)
    
    # Call the Python C API function to raise the exception in the thread
    res = ctypes.pythonapi.PyThreadState_SetAsyncExc(tid, ctypes.py_object(exctype))
    
    # If the result is 0, the thread ID is invalid
    if res == 0:
        raise ValueError('invalid thread id')
    
    # If the result is not 1, it means more than one thread was affected, which is an error
    if res != 1:
        # Reset the exception state
        ctypes.pythonapi.PyThreadState_SetAsyncExc(tid, None)
        raise SystemError('PyThreadState_SetAsyncExc failed')

def stop_thread(thread):
    """
    Stop a thread.

    This function attempts to stop a running thread by raising a SystemExit exception in the thread.
    It uses the _async_raise function to achieve this.

    Args:
        thread (threading.Thread): The thread to be stopped.
    """
    print('Stopping thread...')
    _async_raise(thread.ident, SystemExit)

def camUpFunction(num):
    """
    Move camera up.

    This function adjusts the camera's vertical position by decreasing the pulse width.
    It ensures that the camera does not move beyond its lower limit.

    Args:
        num (int): The amount to decrease the pulse width by.
    """
    global updownpulse
    # Decrease the pulse width by the specified amount
    updownpulse -= num
    # Calculate the new angle for the servo
    angle2 = int((updownpulse - 500) / 10)
    # Ensure the angle does not go below 20 degrees
    if angle2 < 20:
        angle2 = 20
    # Control the servo to move to the new angle
    car.Ctrl_Servo(2, angle2)

def camDownFunction(num):
    """Move camera down."""
    global updownpulse
    updownpulse += num
    angle2 = int((updownpulse - 500) / 10)
    if angle2 > 170:
        angle2 = 170
        car.Ctrl_Servo(2, angle2)

def camLeftFunction(num):
    """Move camera left."""
    global leftrightpulse
    leftrightpulse += num
    angle1 = int((leftrightpulse - 500) / 10)
    if angle1 > 170:
        angle1 = 170
    car.Ctrl_Servo(1, angle1)

def camRightFunction(num):
    """Move camera right."""
    global leftrightpulse
    leftrightpulse -= num
    angle1 = int((leftrightpulse - 500) / 10)
    if angle1 < 20:
        angle1 = 20
    car.Ctrl_Servo(1, angle1)

def camservoInitFunction():
    """Initialize camera servo."""
    global updownpulse, leftrightpulse
    leftrightpulse = 1400
    updownpulse = 1400
    angle1 = int((leftrightpulse - 500) / 10)
    angle2 = int((updownpulse - 500) / 10)
    car.Ctrl_Servo(1, angle1)
    car.Ctrl_Servo(2, angle2)

def bgr8_to_jpeg(value, quality=75):
    """Convert BGR8 image to JPEG."""
    return bytes(cv2.imencode('.jpg', value)[1])

def cv2ImgAddText(img, text, left, top, textColor=(0, 255, 0), textSize=20):
    """Add text to an image."""
    if isinstance(img, np.ndarray):
        img = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    draw = ImageDraw.Draw(img)
    fontStyle = ImageFont.truetype('/home/pi/research_project/dal/dal/simhei.ttf', textSize, encoding='utf-8')
    draw.text((left, top), text, textColor, font=fontStyle)
    return cv2.cvtColor(np.asarray(img), cv2.COLOR_RGB2BGR)

def send_msg(conn, msg_bytes):
    """Send a message through a socket connection."""
    token = b'\x81'
    length = len(msg_bytes)
    if length < 126:
        token += struct.pack('B', length)
    else:
        pass
        if length <= 65535:
            token += struct.pack('!BH', 126, length)
        else:
            token += struct.pack('!BQ', 127, length)
    msg = token + msg_bytes
    conn.send(msg)
    return True

def mode_handle():
    """Handle different modes of operation."""
    global g_camera, prev_right, prev_left, qrcode_data, meanshift_update_flag, LED1_state, gesture_date

    g_camera = cv2.VideoCapture(0)
    g_camera.set(3, 320)
    g_camera.set(4, 240)
    g_camera.set(5, 30)
    g_camera.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter.fourcc('M', 'J', 'P', 'G'))
    g_camera.set(cv2.CAP_PROP_BRIGHTNESS, 62)
    g_camera.set(cv2.CAP_PROP_CONTRAST, 63)
    g_camera.set(cv2.CAP_PROP_EXPOSURE, 4800)

    update_hsv = HSV_Config.update_hsv()
    xservo_pid = PID.PositionalPID(1.1, 0.2, 0.8)
    yservo_pid = PID.PositionalPID(0.8, 0.2, 0.8)
    Z_axis_pid = PID.PositionalPID(0.5, 0, 1)
    direction_pid = PID.PositionalPID(0.8, 0, 0.8)
    speed_pid = PID.PositionalPID(2.1, 0, 0.8)
    face_haar = cv2.CascadeClassifier('123.xml')
    sess = tf.compat.v1.Session(graph=detection_graph)

    fps = 0
    t_start = time.time()

    while g_mode == 'auto_drive':
        if g_camera.get(cv2.CAP_PROP_FRAME_WIDTH) != 640:
            g_camera.release()
            g_camera = cv2.VideoCapture(0)
            g_camera.set(3, 640)
            g_camera.set(4, 480)
            g_camera.set(5, 30)
            g_camera.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter.fourcc('M', 'J', 'P', 'G'))
            g_camera.set(cv2.CAP_PROP_BRIGHTNESS, 60)
        else:
            if g_camera.get(cv2.CAP_PROP_FRAME_WIDTH) != 320:
                g_camera.release()
                g_camera = cv2.VideoCapture(0)
                g_camera.set(3, 320)
                g_camera.set(4, 240)
                g_camera.set(5, 30)
                g_camera.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter.fourcc('M', 'J', 'P', 'G'))
                g_camera.set(cv2.CAP_PROP_BRIGHTNESS, 62)
                g_camera.set(cv2.CAP_PROP_CONTRAST, 63)
                g_camera.set(cv2.CAP_PROP_EXPOSURE, 4800)

        retval, frame = g_camera.read()
        if not retval:
            LED1_state = not LED1_state
            GPIO.output(LED1, LED1_state)
            time.sleep(0.05)
            print('read camera err!')
        else:
            fps += 1
            mfps = fps / (time.time() - t_start)
            if g_mode != 'target_track' or g_target_mode == 'face_track':
                gray_img = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
                faces = face_haar.detectMultiScale(gray_img)
                if len(faces) > 0:
                    face_x, face_y, face_w, face_h = faces[0]
                    cv2.rectangle(frame, (face_x, face_y), (face_x + face_w, face_y + face_h), (0, 255, 0), 2)
            elif g_target_mode == 'color_track':
                pass
            elif g_mode == 'target_detdect':
                if g_detdect_mode == 'face_detect':
                    gray_img = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
                    faces = face_haar.detectMultiScale(gray_img)
                    if len(faces) > 0:
                        face_x, face_y, face_w, face_h = faces[0]
                        cv2.rectangle(frame, (face_x, face_y), (face_x + face_w, face_y + face_h), (0, 255, 0), 2)
                elif g_detdect_mode == 'color_detect':
                    pass
            elif g_mode in ['tag_identification', 'tag_identification_control']:
                if g_tag_select == 'qrcode' or g_detect_control_mode == 'qrcode_control':
                    gray_img = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
                    barcodes = pyzbar.decode(gray_img)
                    if g_mode == 'tag_identification_control' and len(barcodes) == 0:
                        qrcode_data = 'stop'
                    for barcode in barcodes:
                        x, y, w, h = barcode.rect
                        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 225, 0), 2)
                        barcodeData = barcode.data.decode('utf-8')
                        barcodeType = barcode.type
                        text = '{} ({})'.format(barcodeData, barcodeType)
                        cv2.putText(frame, text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (225, 225, 0), 2)
                elif g_tag_select == 'object':
                    image_np_expanded = np.expand_dims(frame, axis=0)
                    image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')
                    detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')
                    detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')
                    detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')
                    num_detections = detection_graph.get_tensor_by_name('num_detections:0')
                    boxes, scores, classes, num = sess.run(
                        [detection_boxes, detection_scores, detection_classes, num_detections],
                        feed_dict={image_tensor: image_np_expanded}
                    )
                    vis_utils.visualize_boxes_and_labels_on_image_array(
                        frame, np.squeeze(boxes), np.squeeze(classes).astype(np.int32),
                        np.squeeze(scores), category_index, use_normalized_coordinates=True,
                        line_thickness=8
                    )
                elif g_tag_select == 'gesture' or g_detect_control_mode == 'gesture_control':
                    raw = str(client_body.gesture(bgr8_to_jpeg(frame)))
                    text = demjson.decode(raw)
                    try:
                        res = text['result'][0]['classname']
                        frame = cv2ImgAddText(frame, hand[res], 10, 30, (0, 255, 0), 30)
                    except:
                        frame = cv2ImgAddText(frame, 'Frame', 10, 30, (0, 0, 255), 30)

            if g_mode != 'auto_drive':
                cv2.putText(frame, 'FPS:  ' + str(int(mfps)), (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)
            stringData = (cv2.imencode('.jpg', frame)[1].tobytes() + b'--frame\r\nContent-Type: text/plain\r\n\r\n' + stringData + b'\r\n')
            yield (b'--frame\r\n'
                   b'Content-Type: image/jpeg\r\n\r\n' + stringData + b'\r\n')

def getip():
    """Get the IP address of the device."""
    try:
        s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        s.connect(('www.baidu.com', 0))
        ip = s.getsockname()[0]
    except Exception as e:
        print(f"Error getting IP: {e}")
        ip = 'x.x.x.x'
    finally:
        s.close()
    return ip

def start_tcp_server(port):
    """Start a TCP server."""
    global g_init, g_socket
    try:
        g_init = True
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
        ip = getip()
        print('GETIP')
        while ip == 'x.x.x.x':
            time.sleep(5)
            ip = getip()
        print(ip)
        sock.bind((ip, port))
        sock.listen(5)
        r_list = [sock]
        while True:
            rl, wl, error = select.select(r_list, [], [], 1)
            for fd in rl:
                if fd is sock:
                    conn, addr = sock.accept()
                    print(f"Connection from {addr}")
                    threading.Thread(target=message_handle, args=(conn,)).start()
                else:
                    data = fd.recv(1024)
                    if not data:
                        r_list.remove(fd)
                        fd.close()
                    else:
                        print(f"Received data: {data}")
    except Exception as e:
        print(f"Error starting TCP server: {e}")
    finally:
        print('finally')
        g_init = False
        sock.close()

def waitClose(sock):
    """Wait and close the socket."""
    time.sleep(10)
    print('sock close')
    sock.close()

def message_handle(client):
    """Handle incoming messages from the client."""
    lastCmd = ''
    while True:
        try:
            info = client.recv(8096)
        except Exception as e:
            print(f"Error receiving data: {e}")
            info = None
        if not info:
            print('break thread')
            break
        payload_len = info[1] & 127
        print(f"Payload length: {payload_len}")
        if payload_len == 126:
            payload_len = struct.unpack('>H', info[2:4])[0]
        elif payload_len == 127:
            payload_len = struct.unpack('>Q', info[2:10])[0]
        masks = info[2:6]
        data = bytearray([info[i] ^ masks[i % 4] for i in range(6, 6 + payload_len)])
        message = data.decode('utf-8')
        print(f"Received message: {message}")
        dispatch(client, message)

def dispatch(sock, cmd):
    global color_lower, g_auto_drive_switch, g_detdect_mode, g_detect_control_mode
    global g_mode, g_presentation_mode, leftrightpulse, color_upper, meanshift_update_flag
    global g_target_mode, g_track_mode, updownpulse, g_motormode, color_hsv, meanshift_X
    global car_speed, meanshift_Y, g_servormode, g_connect_wifi_switch, g_drive_view_switch
    global g_tag_select

    cmd_function = cmd[1:3]
    cmd_map = {
        '01': handle_cmd_01,
        '02': handle_cmd_02,
        '03': handle_cmd_03,
        '04': handle_cmd_04,
        '07': handle_cmd_07,
        '09': handle_cmd_09,
        '10': handle_cmd_10,
        '12': handle_cmd_12,
        '13': handle_cmd_13,
        '14': handle_cmd_14,
        '15': handle_cmd_15,
        '16': handle_cmd_16,
        '17': handle_cmd_17,
        '18': handle_cmd_18,
        '19': handle_cmd_19,
    }

    handler = cmd_map.get(cmd_function)
    if handler:
        handler(cmd)
    else:
        print(f'Unknown command function: {cmd_function}')

def handle_cmd_01(cmd):
    reg = re.compile(r'^\$01,(?P<Car_state>[^ ]*)#')
    regMatch = reg.match(cmd)
    if regMatch:
        Car_state = regMatch.group('Car_state')
        g_motormode = {
            '0': 'car_stop',
            '1': 'car_forward',
            '2': 'car_back',
            '3': 'car_left',
            '4': 'car_right',
            '5': 'car_spin_left',
            '6': 'car_spin_right'
        }.get(Car_state, 'Unknown')
    else:
        print('cmd-01 expression parse failure!')

def handle_cmd_02(cmd):
    reg = re.compile(r'^\$02,(?P<Buzzer_state>[^ ]*)#')
    regMatch = reg.match(cmd)
    if regMatch:
        Buzzer_state = regMatch.group('Buzzer_state')
        if Buzzer_state == '0':
            p.stop()
        elif Buzzer_state == '1':
            p.start(90)
    else:
        print('cmd-02 expression parse failure!')

def handle_cmd_03(cmd):
    reg = re.compile(r'^\$03,(?P<Servo_action>[^ ]*)#')
    regMatch = reg.match(cmd)
    if regMatch:
        Servo_action = regMatch.group('Servo_action')
        g_servormode = {
            '1': 'servo_forward',
            '2': 'servo_down',
            '3': 'servo_left',
            '4': 'servo_right',
            '5': '0',
            '6': 'servo_init'
        }.get(Servo_action, 'Unknown')
    else:
        print('cmd-03 expression parse failure!')

def handle_cmd_04(cmd):
    reg = re.compile(r'^\$04,(?P<Car_speed>[^ ]*)#')
    regMatch = reg.match(cmd)
    if regMatch:
        car_speed = int(regMatch.group('Car_speed'))
    else:
        print('cmd-04 expression parse failure!')

def handle_cmd_07(cmd):
    reg = re.compile(r'^\$07,(?P<Presentation_Mode>[^ ]*)#')
    regMatch = reg.match(cmd)
    if regMatch:
        Presentation_Mode = regMatch.group('Presentation_Mode')
        g_presentation_mode = {
            '0': '0',
            '1': 'ultrasonic',
            '2': 'ultrasonic_IR'
        }.get(Presentation_Mode, 'Unknown')
    else:
        print('cmd-07 expression parse failure!')

def handle_cmd_09(cmd):
    reg = re.compile(r'^\$09,(?P<Track_Mode>[^ ]*)#')
    regMatch = reg.match(cmd)
    if regMatch:
        Track_Mode = regMatch.group('Track_Mode')
        g_track_mode = {
            '0': '0',
            '1': 'tracking',
            '2': 'restricting'
        }.get(Track_Mode, 'Unknown')
    else:
        print('cmd-09 expression parse failure!')

def handle_cmd_10(cmd):
    reg = re.compile(r'^\$10,(?P<target_detdect>[^ ]*)#')
    regMatch = reg.match(cmd)
    if regMatch:
        target_detdect = regMatch.group('target_detdect')
        if target_detdect == '0':
            g_detdect_mode = '0'
        elif target_detdect == '1':
            g_detdect_mode = 'face_detect'
            car.Ctrl_Servo(1, 90)
            car.Ctrl_Servo(2, 60)
        elif target_detdect == '2':
            g_detdect_mode = 'color_detect'
            color_hsv = {
                'red': ((0, 70, 72), (7, 255, 255)),
                'green': ((54, 109, 78), (77, 255, 255)),
                'blue': ((92, 100, 62), (121, 251, 255)),
                'yellow': ((26, 100, 91), (32, 255, 255))
            }
        elif target_detdect == '3':
            meanshift_X = 140
            meanshift_Y = 100
            meanshift_update_flag = 1
            g_detdect_mode = 'meanshift_track'
    else:
        print('cmd-10 expression parse failure!')

def handle_cmd_12(cmd):
    reg = re.compile(r'^\$12,(?P<target_select>[^ ]*)#')
    regMatch = reg.match(cmd)
    if regMatch:
        target_select = regMatch.group('target_select')
        if target_select == '0':
            g_target_mode = '0'
            reset_target()
        elif target_select == '1':
            set_target_mode('color_track', [0, 43, 89], [7, 255, 255])
        elif target_select == '2':
            set_target_mode('color_track', [54, 109, 78], [77, 255, 255])
        elif target_select == '3':
            set_target_mode('color_track', [92, 100, 62], [121, 251, 255])
        elif target_select == '4':
            set_target_mode('color_track', [26, 100, 91], [32, 255, 255])
        elif target_select == '5':
            g_mode = 'target_track'
            g_target_mode = 'face_track'
            car.Ctrl_Servo(1, 90)
            car.Ctrl_Servo(2, 60)
    else:
        print('cmd-12 expression parse failure!')

def handle_cmd_13(cmd):
    reg = re.compile(r'^\$13,(?P<Recognize_option>[^ ]*)#')
    regMatch = reg.match(cmd)
    if regMatch:
        Recognize_option = regMatch.group('Recognize_option')
        g_tag_select = {
            '0': '0',
            '1': 'qrcode',
            '2': 'object',
            '3': 'gesture'
        }.get(Recognize_option, 'Unknown')
        if Recognize_option == '1':
            print('qrcoderead')
    else:
        print('cmd-13 expression parse failure!')

def handle_cmd_14(cmd):
    reg = re.compile(r'^\$14,(?P<wifi_switch>[^ ]*)#')
    regMatch = reg.match(cmd)
    if regMatch:
        wifi_switch = regMatch.group('wifi_switch')
        g_connect_wifi_switch = 'open' if wifi_switch == '1' else 'close'
    else:
        print('cmd-15 expression parse failure!')

def handle_cmd_15(cmd):
    reg = re.compile(r'^\$15,(?P<Auto_drive_state>[^ ]*)#')
    regMatch = reg.match(cmd)
    if regMatch:
        Auto_drive_state = regMatch.group('Auto_drive_state')
        if Auto_drive_state == '0':
            g_auto_drive_switch = 'close'
            car.Car_Stop()
        elif Auto_drive_state == '1':
            g_auto_drive_switch = 'open'
    else:
        print('cmd-16 expression parse failure!')

def handle_cmd_17(cmd):
    reg = re.compile(r'^\$17,(?P<color_select>[^ ]*)#')
    regMatch = reg.match(cmd)
    if regMatch:
        color_select = regMatch.group('color_select')
        if color_select == '0':
            g_target_mode = '0'
            reset_target()
        elif color_select == '1':
            set_target_mode('color_follow', [0, 43, 89], [7, 255, 255])
        elif color_select == '2':
            set_target_mode('color_follow', [54, 109, 78], [77, 255, 255])
    else:
        print('cmd-19 expression parse failure!')

def reset_target():
    target_valuex = target_valuey = 1400
    angle1 = int((target_valuex - 500) / 10)
    angle2 = int((target_valuey - 500) / 10)
    car.Ctrl_Servo(1, angle1)
    car.Ctrl_Servo(2, angle2)
    car.Car_Stop()

def set_target_mode(mode, lower, upper):
    global g_mode, g_target_mode, color_lower, color_upper
    g_mode = 'target_track'
    g_target_mode = mode
    color_lower = np.array(lower)
    color_upper = np.array(upper)
    reset_target()

def reset_all_modes():
    global g_mode, g_presentation_mode, g_track_mode, g_detdect_mode, g_target_mode
    global g_tag_select, g_detect_control_mode, g_auto_drive_switch, g_drive_view_switch
    g_mode = g_presentation_mode = g_track_mode = g_detdect_mode = g_target_mode = '0'
    g_tag_select = g_detect_control_mode = '0'
    g_auto_drive_switch = 'close'
    g_drive_view_switch = 0
    car.Car_Stop()
    GPIO.output(Avoid_ON, GPIO.LOW)

def set_remote_control_mode():
    global g_mode, leftrightpulse, updownpulse
    g_mode = 'remote_control'
    leftrightpulse = updownpulse = 1400
    car.Ctrl_Servo(1, 90)
    car.Ctrl_Servo(2, 90)

def set_target_track_mode():
    global g_mode
    g_mode = 'target_track'
    reset_target()

def set_auto_drive_mode():
    global g_mode, leftrightpulse, updownpulse
    g_mode = 'auto_drive'
    leftrightpulse = 1400
    updownpulse = 2100
    car.Ctrl_Servo(1, 93)
    car.Ctrl_Servo(2, 160)

def getwlanip():
    """
    Function to get the IP address of the wlan0 interface.
    Returns the IP address as a string. If no IP address is found, returns an empty string.
    """
    ip = os.popen('/sbin/ifconfig wlan0 | grep \'inet\' | awk \'{print $2}\'').read().strip()
    if not ip:
        print('No connection found!')
    return ip

def decodeDisplay(image):
    """
    Function to decode barcodes in the given image.
    Draws rectangles around detected barcodes and extracts SSID and PASSWD from the barcode data.
    """
    global PASSWD
    global SSID
    barcodes = pyzbar.decode(image)
    for barcode in barcodes:
        x, y, w, h = barcode.rect
        cv2.rectangle(image, (x, y), (x + w, y + h), (225, 225, 225), 2)
        barcodeData = barcode.data.decode('utf-8')
        barcodeType = barcode.type
        text = '{} ({})'.format(barcodeData, barcodeType)
        cv2.putText(image, text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2)
        a = barcodeData.find('SSID')
        b = barcodeData.find('|')
        SSID = barcodeData[6:b - 1]
        PASSWD = barcodeData[b + 2:]
        print(f'SSID: {SSID}')
        print(f'PASSWD: {PASSWD}')
        print(f'[INFO] Found {barcodeType} barcode: {barcodeData}')
    return image

def detect():
    """
    Function to detect and decode barcodes using the camera.
    Continuously captures frames from the camera and decodes barcodes to extract SSID and PASSWD.
    """
    global PASSWD
    global LED1_state
    global SSID
    SSID = ''
    PASSWD = ''
    camera = cv2.VideoCapture(0)
    while True:
        GPIO.output(LED2, GPIO.LOW)
        time.sleep(0.02)
        GPIO.output(LED2, GPIO.HIGH)
        time.sleep(0.02)
        ret, frame = camera.read()
        if not ret:
            LED1_state = not LED1_state
            time.sleep(0.05)
            GPIO.output(LED1, LED1_state)
            print('Read error')
            continue
        if getip() != 'x.x.x.x':
            print('GETIP')
            break
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        decodeDisplay(gray)
        if SSID and PASSWD:
            os.system('sudo pkill wpa_supplicant')
            cmd = f'sudo wpa_passphrase {SSID} {PASSWD} > /etc/wpa_supplicant/wpa_supplicant.conf'
            os.system(cmd)
            os.system('wpa_supplicant -B -i wlan0 -c /etc/wpa_supplicant/wpa_supplicant.conf &')
            print('Decoded')
            break
    camera.release()

def detect_change():
    """
    Function to detect and decode barcodes using the camera.
    Similar to detect(), but used for changing the WiFi connection.
    """
    global PASSWD
    global LED1_state
    global SSID
    SSID = ''
    PASSWD = ''
    camera = cv2.VideoCapture(0)
    while True:
        GPIO.output(LED2, GPIO.LOW)
        time.sleep(0.02)
        GPIO.output(LED2, GPIO.HIGH)
        time.sleep(0.02)
        ret, frame = camera.read()
        if not ret:
            LED1_state = not LED1_state
            time.sleep(0.05)
            GPIO.output(LED1, LED1_state)
            print('Read error')
            continue
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        decodeDisplay(gray)
        if SSID and PASSWD:
            os.system('sudo pkill wpa_supplicant')
            cmd = f'sudo wpa_passphrase {SSID} {PASSWD} > /etc/wpa_supplicant/wpa_supplicant.conf'
            os.system(cmd)
            os.system('wpa_supplicant -B -i wlan0 -c /etc/wpa_supplicant/wpa_supplicant.conf &')
            print('Decoded')
            break
    camera.release()

def Distance():
    """
    Function to measure the distance using an ultrasonic sensor.
    Sends a trigger pulse and measures the time for the echo to return.
    Returns the distance in centimeters.
    """
    GPIO.output(TrigPin, GPIO.LOW)
    time.sleep(2e-06)
    GPIO.output(TrigPin, GPIO.HIGH)
    time.sleep(1.5e-05)
    GPIO.output(TrigPin, GPIO.LOW)
    t3 = time.time()
    while not GPIO.input(EchoPin):
        t4 = time.time()
        if t4 - t3 > 0.03:
            return -1
    t1 = time.time()
    while GPIO.input(EchoPin):
        t5 = time.time()
        if t5 - t1 > 0.03:
            return -1
    t2 = time.time()
    return (t2 - t1) * 340 / 2 * 100

def Distance_test():
    """
    Function to test the distance measurement.
    Takes multiple measurements and returns the average distance.
    Handles errors and retries if necessary.
    """
    num = 0
    ultrasonic = []
    time_first = time.time()
    while num < 5:
        distance = Distance()
        while distance == -1:
            distance = Distance()
            if time.time() - time_first > 5:
                print('Ultrasonic sensor error')
                return 0
        while distance >= 500 or distance == 0:
            distance = Distance()
            if time.time() - time_first > 5:
                print('Distance measurement error')
                return 0
        ultrasonic.append(distance)
        num += 1
    distance = (ultrasonic[1] + ultrasonic[2] + ultrasonic[3]) / 3
    return distance

def ultrasonic_reply():
    """
    Function to send the distance measured by the ultrasonic sensor to the connected socket.
    The function measures the distance, formats it into a specific message format, and sends the message through the socket.
    """
    distance = Distance_test()
    # Format the distance into a message string
    # The message format is: $05,<distance>#
    temp = f'$05,{int(distance)}#'
    # Send the formatted message through the socket
    send_msg(g_socket, temp.encode('utf-8'))

def u_avoid():
    """
    Function to handle obstacle avoidance using the ultrasonic sensor.
    The car will stop and spin right if an obstacle is detected within 30 cm, otherwise it will continue to run forward.
    """
    distance = Distance_test()
    if distance < 30:
        # Obstacle detected within 30 cm
        car.Car_Stop()
        time.sleep(0.1)
        car.Car_Spin_Right(100, 100)
        time.sleep(0.5)
    else:
        # No obstacle detected within 30 cm
        car.Car_Run(100, 100)

def IR_reply():
    """
    Function to send the state of the infrared sensors to the connected socket.
    The function reads the values of the left and right infrared sensors, formats
    them into a specific message format, and sends the message through the socket.
    """
    # Read the state of the left and right infrared sensors
    LeftSensorValue = GPIO.input(AvoidSensorLeft)
    RightSensorValue = GPIO.input(AvoidSensorRight)
    
    # Format the sensor values into a message string
    # The message format is: $06,<LeftSensorValue>,<RightSensorValue>#
    temp = f'$06,{1 - LeftSensorValue},{1 - RightSensorValue}#'
    
    # Send the formatted message through the socket
    send_msg(g_socket, temp.encode('utf-8'))

def ui_avoid():
    """
    Function to handle obstacle avoidance using both ultrasonic and infrared sensors.
    The car will take different actions based on the distance measured by the ultrasonic sensor
    and the state of the left and right infrared sensors.
    """
    distance = Distance_test()
    LeftSensorValue = GPIO.input(AvoidSensorLeft)
    RightSensorValue = GPIO.input(AvoidSensorRight)

    if distance < 25:
        if not LeftSensorValue and not RightSensorValue:
            # Both sensors detect an obstacle
            car.Car_Stop()
            time.sleep(0.1)
            car.Car_Spin_Right(100, 100)
            time.sleep(1)
        elif LeftSensorValue and not RightSensorValue:
            # Only the left sensor detects an obstacle
            car.Car_Stop()
            time.sleep(0.1)
            car.Car_Spin_Left(80, 80)
            time.sleep(1)
            if not GPIO.input(AvoidSensorLeft) and GPIO.input(AvoidSensorRight):
                car.Car_Stop()
                time.sleep(0.1)
                car.Car_Spin_Right(90, 90)
                time.sleep(2)
        elif not LeftSensorValue and RightSensorValue:
            # Only the right sensor detects an obstacle
            car.Car_Stop()
            time.sleep(0.1)
            car.Car_Spin_Right(80, 80)
            time.sleep(1)
            if GPIO.input(AvoidSensorLeft) and not GPIO.input(AvoidSensorRight):
                car.Car_Stop()
                time.sleep(0.1)
                car.Car_Spin_Left(90, 90)
                time.sleep(2)
        elif LeftSensorValue and RightSensorValue:
            # Both sensors do not detect an obstacle
            car.Car_Stop()
            time.sleep(0.1)
            car.Car_Spin_Right(80, 80)
            time.sleep(0.5)
    else:
        if not LeftSensorValue and not RightSensorValue:
            # Both sensors detect an obstacle
            car.Car_Stop()
            time.sleep(0.1)
            car.Car_Spin_Right(90, 90)
            time.sleep(1)
        elif not LeftSensorValue and RightSensorValue:
            # Only the right sensor detects an obstacle
            car.Car_Stop()
            time.sleep(0.1)
            car.Car_Spin_Right(80, 80)
            time.sleep(0.5)
        elif LeftSensorValue and not RightSensorValue:
            # Only the left sensor detects an obstacle
            car.Car_Stop()
            time.sleep(0.1)
            car.Car_Spin_Left(80, 80)
            time.sleep(0.5)
        else:
            # No obstacles detected
            car.Car_Run(100, 100)

def motion_refresh():
    global gesture_date, g_servormode, qrcode_data
    print('refresh！')

    while g_mode == 'remote_control':
        handle_servo_mode()
        handle_motor_mode()
        handle_presentation_mode()
        handle_track_mode()
        handle_qrcode_data()
        handle_gesture_control()
        handle_auto_drive()

def handle_servo_mode():
    if g_servormode == 'servo_forward':
        camUpFunction(3)
    elif g_servormode == 'servo_down':
        camDownFunction(3)
    elif g_servormode == 'servo_left':
        camLeftFunction(3)
    elif g_servormode == 'servo_right':
        camRightFunction(3)
    elif g_servormode == 'servo_init':
        g_servormode = '0'
        camservoInitFunction()

def handle_motor_mode():
    if g_motormode == 'car_forward':
        car.Car_Run(int(car_speed), int(car_speed))
    elif g_motormode == 'car_back':
        car.Car_Back(int(car_speed), int(car_speed))
    elif g_motormode == 'car_left':
        car.Car_Run(int(car_speed / 2), int(car_speed))
    elif g_motormode == 'car_right':
        car.Car_Run(int(car_speed), int(car_speed / 2))
    elif g_motormode == 'car_spin_left':
        car.Car_Spin_Left(int(car_speed), int(car_speed))
    elif g_motormode == 'car_spin_right':
        car.Car_Spin_Right(int(car_speed), int(car_speed))
    elif g_motormode == 'car_stop':
        car.Car_Stop()

def handle_presentation_mode():
    if g_mode == 'presentation':
        if g_presentation_mode == 'ultrasonic':
            u_avoid()
        elif g_presentation_mode == 'ultrasonic_IR':
            ui_avoid()
        else:
            car.Car_Stop()
            
# Create a new thread for the motion_refresh function
motion_refresh_id = threading.Thread(target=motion_refresh)
# Set the thread as a daemon so it will automatically close when the main program exits
motion_refresh_id.setDaemon(True)
# Start the motion_refresh thread
motion_refresh_id.start()

def state_reflash():
    global g_connect_wifi_switch
    print('reflash_state!')
    
    while True:
        if g_mode == 'remote_control':
            ultrasonic_reply()
        elif g_mode == 'presentation':
            ultrasonic_reply()
            IR_reply()
        elif g_mode == 'track_mode':
            tracking_reply()
        elif g_mode == '0':
            handle_mode_zero()
        else:
            handle_other_modes()
        
        time.sleep(1)

def handle_mode_zero():
    ip = getip()
    if ip == 'x.x.x.x':
        handle_no_ip()
    elif g_connect_wifi_switch == 'open':
        handle_wifi_open()

def handle_no_ip():
    p.start(50)
    time.sleep(1)
    p.stop()
    try:
        g_camera.release()
        print('g_camera released')
    except Exception as e:
        print(f'g_camera release failed: {e}')
    detect()
    print('detected')
    try:
        stop_thread(tid)
        print('stop thread')
    except Exception as e:
        print(f'stop thread failed: {e}')
    p.start(99)
    time.sleep(0.5)
    p.stop()
    time.sleep(0.5)
    p.start(99)
    time.sleep(0.5)
    p.stop()
    wait_for_ip()

def handle_wifi_open():
    p.start(50)
    time.sleep(1)
    p.stop()
    try:
        g_camera.release()
        print('g_camera released')
    except Exception as e:
        print(f'g_camera release failed: {e}')
    detect_change()
    print('识别成功！！！')
    try:
        stop_thread(tid)
        print('stop thread')
    except Exception as e:
        print(f'stop thread failed: {e}')
    p.start(99)
    time.sleep(0.5)
    p.stop()
    time.sleep(0.5)
    p.start(99)
    time.sleep(0.5)
    p.stop()
    g_connect_wifi_switch = 'close'
    wait_for_ip()

def wait_for_ip(timeout=30):
    """Wait for the device to obtain an IP address."""
    start_time = time.time()
    ip = getip()
    while ip == 'x.x.x.x':
        if time.time() - start_time > timeout:
            print('WiFi timeout')
            return False
        time.sleep(0.5)
        ip = getip()
    GPIO.output(LED2, GPIO.HIGH)
    time.sleep(1)
    return True

def getip():
    """Get the IP address of the device."""
    try:
        s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        s.connect(('www.baidu.com', 0))
        ip = s.getsockname()[0]
    except:
        ip = 'x.x.x.x'
    finally:
        s.close()
    return ip

MODEL_NAME = '/home/pi/research_project/dal/dal/ssdlite_mobilenet_v2_coco_2018_05_09'
PATH_TO_CKPT = os.path.join(MODEL_NAME, 'frozen_inference_graph.pb')
NUM_CLASSES = 90
IMAGE_SIZE = (12, 8)

# Check if the model file exists
if not os.path.isfile(PATH_TO_CKPT):
    print('Model does not exist!')
    exit(1)

print('Loading Graph...')
detection_graph = tf.Graph()
with detection_graph.as_default():
    od_graph_def = tf.compat.v1.GraphDef()
    with tf.io.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:
        serialized_graph = fid.read()
        od_graph_def.ParseFromString(serialized_graph)
        tf.import_graph_def(od_graph_def, name='')

# Load label map
PATH_TO_LABELS = os.path.join(MODEL_NAME, 'label_map.pbtxt')
label_map = label_map_util.load_labelmap(PATH_TO_LABELS)
categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)
category_index = label_map_util.create_category_index(categories)
print('Finished Loading Graph.')

# GPIO setup
def setup_gpio():
    GPIO.setmode(GPIO.BOARD)
    GPIO.setwarnings(False)
    GPIO.setup(LED2, GPIO.OUT, initial=GPIO.HIGH)
    GPIO.setup(LED1, GPIO.OUT, initial=GPIO.LOW)
    GPIO.setup(Buzzer, GPIO.OUT)
    GPIO.setup(EchoPin, GPIO.IN)
    GPIO.setup(TrigPin, GPIO.OUT)
    GPIO.setup(AvoidSensorLeft, GPIO.IN)
    GPIO.setup(AvoidSensorRight, GPIO.IN)
    GPIO.setup(Avoid_ON, GPIO.OUT)
    GPIO.setup(Tracking_Left1, GPIO.IN)
    GPIO.setup(Tracking_Left2, GPIO.IN)
    GPIO.setup(Tracking_Right1, GPIO.IN)
    GPIO.setup(Tracking_Right2, GPIO.IN)

# Main function
def main():
    setup_gpio()
    p = GPIO.PWM(Buzzer, 440)
    
    if getip() != 'x.x.x.x':
        p.start(50)
        time.sleep(1)
        p.stop()
        GPIO.output(LED2, GPIO.HIGH)
        camservoInitFunction()
    
    state_refresh_thread = threading.Thread(target=state_reflash)
    state_refresh_thread.daemon = True
    state_refresh_thread.start()

    app.run('0.0.0.0', port=6001, debug=False)

if __name__ == '__main__':
    main()